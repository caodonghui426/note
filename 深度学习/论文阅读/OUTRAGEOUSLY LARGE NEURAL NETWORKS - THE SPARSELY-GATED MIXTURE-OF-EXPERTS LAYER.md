# 1.摘要
神经网络吸收信息的能力受其参数数量限制。有条件计算理论上被提出作为一种在不增加计算量的情况下显著增加模型容量的方法。然而，在实践中存在重大的算法和性能挑战。在这项工作中，我们解决了这些挑战，并最终实现了条件计算的承诺，在现代GPU集群上仅损失少量计算效率的情况下，使模型容量提高超过1000倍。我们引入了一个稀疏门控混合专家层（MoE），由多达数千个前馈子网络组成。可训练的门控网络确定每个示例要使用哪些专家进行稀疏组合。我们将MoE应用于语言建模和机器翻译任务中，其中模型容量对于吸收训练语料库中丰富知识至关重要。我们提出了一种模型架构，在堆叠LSTM层之间以卷积方式应用MoE，该MoE具有多达1370亿个参数。在大规模语言建模和机器翻译基准测试中，这些模型以较低的计算成本取得了明显优于最先进方法的结果。
# 2.结论
这项工作是首次展示了在深度网络中通过条件计算取得的重大突破。我们仔细确定了条件计算的设计考虑和挑战，并通过算法和工程解决方案来应对它们。尽管我们专注于文本，但只要有足够大的训练集，条件计算也可能在其他领域发挥作用。我们期待未来能看到许多新颖的条件计算实现和应用。
# 3.引言
## 3.1 条件计算
在深度学习的成功中，利用训练数据和模型规模的扩展起到了核心作用。当数据集足够大时，增加神经网络的容量（参数数量）可以提供更好的预测准确性。这已经在文本领域（Sutskever等人，2014年；Bahdanau等人，2014年；Jozefowicz等人，2016年；Wu等人，2016年）、图像领域（Krizhevsky等人，2012年；Le等人，2012年）和音频领域（Hinton等人，2012年；Amodei等人, 2015) 中得到证明。对于典型的深度学习模型，在每个示例上激活整个模型会导致训练成本呈近似二次增长，因为模型大小和训练示例数都在增加。不幸的是，并行计算能力和分布式计算方面取得的进展还无法满足这种需求。
各种形式的条件计算被提出作为一种增加模型容量而不需要成比例增加计算成本的方法（Davis＆Arel，2013年; Bengio等人，2013年; Eigen等人，2013年; Ludovic Denoyer，2014年; Cho＆Bengio， 2014年; Bengio等人，2015年; Almahairi等人，2015）。在这些方案中，网络的大部分部分根据每个示例是活动还是非活动。门控决策可以是二进制或稀疏和连续的、随机或确定性的。提出了各种形式的强化学习和反向传播来训练门控决策。
虽然这些想法在理论上很有前景，但迄今为止还没有任何工作能够展示出模型容量、训练时间或模型质量的巨大改进。我们将此归因于以下挑战的结合：
- 现代计算设备，尤其是GPU，在算术方面比分支更快。以上大部分工作都认识到了这一点，并提议通过每个门控决策打开/关闭网络中的大块。
- 大批次大小对性能至关重要，因为它们摊销了参数传输和更新的成本。条件计算减少了网络中条件活动块的批次大小。
- 网络带宽可能成为瓶颈。一组GPU的计算能力可能比设备间聚合网络带宽高出数千倍。为了在计算上高效，一个算法相对于网络需求与计算需求之比必须超过该比例。嵌入层可以看作是一种条件计算形式，但受到这个问题的限制。由于嵌入通常需要通过网络发送，所以（例如参数）交互数量受到网络带宽而不是计算容量的限制。
- 根据方案不同，损失项可能需要用来实现每个块和/或每个样本所需稀疏度的目标。Bengio等人（2015）使用了三个这样的项。这些问题可能会影响模型质量和负载平衡。
- 模型容量对于非常大的数据集最为关键。现有关于条件计算的文献处理相对较小的图像识别数据集，其中包含多达600,000张图像。很难想象这些图像的标签能够提供足够信号来充分训练具有数百万甚至数十亿参数的模型。
在本工作中，我们首次解决了上述所有挑战，并最终实现了条件计算的承诺。我们在模型容量方面获得超过1000倍改进，仅在计算效率方面稍微损失，并显著推动公共语言建模和翻译数据集领域取得了最新技术成果。
## 3.2 我们的方法：稀疏门控混合专家层
我们对条件计算的方法是引入一种新型的通用神经网络组件：稀疏门控专家混合层（MoE）。MoE由多个专家组成，每个专家都是一个简单的前馈神经网络，并且有一个可训练的门控网络，它选择稀疏组合来处理每个输入（见图1）。整个网络的所有部分都通过反向传播进行联合训练。
尽管引入的技术是通用的，但在本文中我们专注于语言建模和机器翻译任务，这些任务已被证明受益于非常大的模型。特别地，在堆叠LSTM层（Hochreiter＆Schmidhuber, 1997）之间应用了一个MoE卷积，如图1所示。 MoE在文本中的每个位置调用一次，并在每个位置选择潜在不同组合的专家。不同的专家倾向于根据语法和语义而变得高度专业化（见附录E表9）。在语言建模和机器翻译基准测试中，我们以较小计算成本取得了比最佳已发表结果更好的改进。
![](img/CleanShot%202023-10-24%20at%2019.13.25@2x.png)
> 图1：混合专家（MoE）层嵌入在一个循环语言模型中。在这种情况下，稀疏门控函数选择两个专家进行计算。他们的输出由门控网络的输出调制。
## 3.3 MoE的相关工作
自从二十多年前引入混合专家方法以来（Jacobs等，1991; Jordan＆Jacobs，1994），它一直是许多研究的主题。已经提出了不同类型的专家架构，如SVMs（Collobert等人，2002）、高斯过程（Tresp, 2001; Theis＆Bethge, 2015; Deisenroth＆Ng, 2015）、Dirichlet过程（Shahbaba＆Neal, 2009）和深度网络。其他工作集中在不同的专家配置上，例如分层结构（Yao等人，2009）、无限数量的专家（Rasmussen＆Ghahramani, 2002）和逐步添加专家（Aljundi等人，2016）。Garmash和Monz (2016) 提出了一个用于机器翻译的混合专家模型。门控网络在预先训练好的集成NMT模型上进行训练。
以上工作涉及顶级混合专家。混合专家是整个模型。Eigen等人(2013)介绍了使用具有自己门控网络的多个MoEs作为深度模型部分的想法。直观地说后一种方法更强大，因为复杂问题可能包含许多子问题，每个子问题都需要不同的专业知识。他们还在结论中暗示了引入稀疏性的潜力，将MoEs转化为计算计算的工具。
我们的工作基于将MoEs用作通用神经网络组件的思想。虽然Eigen等人(2013)使用两个堆叠的MoEs允许进行两组门控决策，但我们对MoE进行卷积应用时可以在文本中每个位置上做出不同的门控决策。我们还实现了稀疏门控并展示其作为大幅增加模型容量的实际方法。
# 4.MoE层结构
混合专家（MoE）层由一组n个“专家网络”E1，· · · ，En和一个“门控网络”G组成，其输出是一个稀疏的n维向量。图1显示了MoE模块的概述。这些专家本身就是神经网络，每个都有自己的参数。虽然原则上我们只需要求得这些专家接受相同大小的输入并产生相同大小的输出，但在本文中我们仅限于模型为具有相同架构但具有不同参数的前馈网络情况下进行初步调查。让我们用$G(x)$ 和$E_i(x)$ 表示给定输入x时门控网络和第i个专家网络的输出。MoE模块的输出y可以写成以下形式：
$$y=\sum_{i=1}^nG(x)_iE_i(x)$$
我们根据G(x)的稀疏性来节省计算。只要$G(x)_i$  = 0，我们就不需要计算$E_i(x)$ 。在我们的实验中，有成千上万个专家，但每个示例只需要评估其中几个。如果专家数量非常大，我们可以通过使用两级分层MoE来减少分支因子。在分层MoE中，主要门控网络选择了“专家”的稀疏加权组合，而每个“专家”本身都是具有自己门控网络的二级混合专家模型。接下来我们将重点讨论普通的MoEs，在附录B中提供关于分层MoEs更多细节。我们的实现与其他条件计算模型相关联。一个以简单权重矩阵作为专家的MoE类似于(Cho & Bengio, 2014)中提出的参数化权重矩阵。一个具有一层隐藏层的MoE类似于(Bengio et al., 2015)中描述的块状dropout，在完全激活层之间夹着被丢弃的层。
## 4.1 门控网络
**Softmax门控：** 一种简单的非稀疏门控函数选择（Jordan＆Jacobs，1994）是将输入乘以可训练的权重矩阵$W_g$ ，然后应用Softmax函数。
$$G_\sigma(x)=Softmax(x\cdot W_g)$$
**噪音的Top-K门控：** 我们在Softmax门控网络中添加了两个组件：稀疏性和噪声。在进行softmax函数之前，我们添加可调节的高斯噪声，然后仅保留前k个值，并将其余部分设置为-∞（这会导致相应的门控值等于0）。稀疏性用于节省计算量，如上所述。虽然这种形式的稀疏性在门控函数输出中创建了一些理论上可怕的不连续性，但我们尚未观察到实际问题。噪声项有助于负载平衡，将在附录A中讨论。每个组件的噪声量由第二个可训练权重矩阵$W_{noise}$ 来控制。
$$\begin{gathered}
G(x)=Softmax(KeepTopK(H(x),k)) \\
 \\
H(x)_i=(x\cdot W_g)_i+StandardNormal()\cdot Softplus((x\cdot W_{noise})_i) \\
KeepTopK(v,k)_i=\begin{cases}v_i&\text{if }v_i\text{ is in the top }k\text{ elements of }v.\\-\infty&\text{otherwise.}\end{cases} 
\end{gathered}$$
# 5.解决性能挑战
## 3.1 缩小批次问题
在现代的CPU和GPU上，为了计算效率，需要使用较大的批量大小，以分摊参数加载和更新的开销。如果门控网络对每个示例选择k个专家中的n个，则对于一个包含b个示例的批次来说，每个专家将接收到一个更小的批次，大约是$\frac{kb}n\ll b$ 个示例。随着专家数量增加，这会导致朴素MoE实现变得非常低效。解决这种缩小批次问题的方法是尽可能地增加原始批量大小。然而，由于存储前向传递和反向传递之间激活值所需内存有限制，因此批量大小往往受到限制。我们提出以下技术来增加批量大小：
**混合数据并行和模型并行：** 在传统的分布式训练环境中，不同设备上的多个模型副本异步处理不同批次的数据，并通过一组参数服务器进行参数同步。在我们的技术中，这些不同批次同时运行，以便可以将它们合并到MoE层中。我们根据传统的数据并行方案分发模型的标准层和门控网络，但只保留每个专家一个共享副本。MoE层中的每个专家接收由所有数据并行输入批次中相关示例组成的合并批次。相同一组设备既充当数据并行副本（用于标准层和门控网络），又充当模型并行碎片（每个碎片包含一部分专家）。如果模型分布在d台设备上，并且每个设备处理大小为b 的批次，则每个专家接收大约$\frac{kbd}{n}$ 个示例构成的批次。因此，我们实现了专家批量大小提高d倍的效果。
在分层MoE的情况下（第B节），主要的门控网络采用数据并行ism，而次级MoEs则采用模型并行ism。每个次级MoE都驻留在一个设备上。这种技术允许我们通过按比例增加训练集群中的设备数量来增加专家数量（从而增加参数数量）。总批量大小增加，保持每个专家的批量大小恒定。每个设备的内存和带宽需求也保持恒定，步骤时间、处理与模型参数数量相等的训练示例所需时间也保持恒定。我们的目标是在万亿字语料库上训练一个万亿参数模型。截至本文撰写时，我们尚未将系统扩展到如此规模，但通过添加更多硬件应该是可能实现的。
**利用卷积性质：** 在我们的语言模型中，我们将相同的MoE应用于前一层的每个时间步。如果我们等待前一层完成，我们可以将MoE作为一个大批次同时应用于所有时间步骤。这样做会使输入批次大小增加到未展开时间步数的倍数。
**增加递归MoE的批处理大小：** 我们怀疑更强大的模型可能涉及递归地应用MoE。例如，LSTM或其他RNN的权重矩阵可以被MoE替换。不幸的是，这种模型打破了上一段中所述的卷积技巧，因为一个时间步长内MoE的输入取决于上一个时间步长内MoE输出。Gruslys等人（2016）描述了一种在展开RNN时极大减少存储激活数量但需要重新计算正向激活值代价较高技术。这将允许批量大小大幅增加。
## 3.2 网络带宽
在分布式计算中，另一个重要的性能问题是网络带宽。由于专家是固定的（见上文），并且门控参数数量较少，大部分通信涉及将专家的输入和输出通过网络发送。为了保持计算效率，专家计算量与其输入和输出大小之比必须超过计算设备的计算与网络容量之比。对于GPU来说，这个比例可能是千倍以上。在我们的实验中，我们使用具有数千个RELU激活单元的隐藏层作为专家。由于专家中权重矩阵的尺寸为$input_{size}×hidden_{size}$ 和$hidden_{size} × output_{size}$ ，因此计算与输入和输出之间的比例等于隐藏层大小。方便地说，我们可以通过使用更大的隐藏层或更多隐藏层来提高计算效率。
# 6.平衡专家使用

我们观察到，门控网络往往会收敛到一个状态，其中它总是为同几个专家产生较大的权重。这种不平衡是自我强化的，因为受青睐的专家训练得更快，从而被门控网络选择得更多。Eigen等人（2013）描述了相同的现象，并在训练开始时使用硬约束来避免这个局部最小值。Bengio等人（2015）对每个门的批次平均值包含了软约束。
我们采用软约束方法。我们定义一个专家相对于一批训练样例的重要性为该专家的门值在该批次上求和。我们定义了额外损失$L_{importance}$ ，将其添加到模型的整体损失函数中。该损失等于重要性值集合变异系数的平方乘以手动调整的缩放因子$w_{importance}$ 。这个额外损失鼓励所有专家具有相等重要性。
$$\begin{gathered}Importance(X)=\sum_{x\in X}G(x)\\\\L_{importance}(X)=w_{importance}\cdot CV(Importance(X))^2\end{gathered}$$
尽管这个损失函数可以确保平等的重要性，但专家们可能仍然会收到非常不同数量的示例。例如，一个专家可能会收到一些具有较大权重的示例，而另一个专家可能会收到许多具有较小权重的示例。这可能导致分布式硬件上的内存和性能问题。为了解决这个问题，我们引入了第二个损失函数Load，它确保负载均衡。附录A包含了该函数的定义以及实验结果。
正态分布（也称为高斯分布）的累积分布函数（CDF）数学公式如下：

对于正态分布的累积分布函数：
$$F(x) = \frac{1}{2} \left(1 + \text{erf}\left(\frac{x - \mu}{\sigma\sqrt{2}}\right)\right)$$
其中：
- $F(x)$ 是累积分布函数值，表示随机变量小于等于\(x\)的概率。
- $\mu$ 是正态分布的均值（期望值）。
- $\sigma$ 是正态分布的标准差。
- x 是随机变量的值。
- $\text{erf}(z)$ 是误差函数，用于计算正态分布的CDF。
- 
正态分布的CDF公式描述了在给定均值和标准差的情况下，随机变量取值小于等于\(x\)的累积概率。这是正态分布的重要特性之一，它描述了数据集中的值在不同位置的概率分布。