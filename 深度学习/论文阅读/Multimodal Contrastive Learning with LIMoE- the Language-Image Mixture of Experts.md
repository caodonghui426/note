# 1.摘要
大型稀疏激活模型在多个领域取得了出色的性能。然而，这些模型通常只能一次训练单一模态。我们提出了语言-图像MoE（LIMoE），这是一个稀疏专家混合模型，能够进行多模态学习。LIMoE同时接受图像和文本，并使用对比损失进行训练。由于专家层可以学习适当的模态划分，所以MoEs非常适合作为多模态骨干网络。然而，也会面临新的挑战；特别是训练稳定性和平衡专家利用度方面，针对此我们提出了基于熵的正则化方案。在多个尺度上，我们展示了与等价计算成本的密集模型相比显著的性能改进。经过类似CLIP-L/14规模训练后，LIMoE-L/16实现了78.6%零样本ImageNet准确率（相较于76.2%），并且通过进一步扩展到H/14（使用额外数据）达到84.1%，与使用更大自定义每种形式骨干网络和预训练方案的最先进方法相媲美。我们分析了LIMoE的定量和定性行为，并展示了模态处理的差异和特定模态专家的有机出现。
# 2.结论和未来工作
我们提出了LIMoE，这是第一个多模态稀疏专家混合模型。我们揭示了与此设置特定的新故障模式，并提出了基于熵的辅助损失，可以稳定训练并产生高性能模型。它适用于许多模型规模，在FLOP匹配的密集基线上平均改进+10.2％零样本准确率。当扩展到大型H/14模型时，我们实现了84.1％的准确率，与当前SOTA方法竞争力相当。
社会影响和局限性：大规模模型[44]、对比度模型[7]和网络规模多媒体数据[45]可能带来潜在危害，在这里同样存在，因为LIMoE没有明确解决这些问题。另一方面，已经表明修剪模型往往会导致低资源群体被遗忘[46]，从而导致某些子群体的性能不成比例地下降。对于我们的专家修剪实验来说值得考虑这一点；但类似地，具有可以深入专业化的专家进行扩展建立更好地应对代表少数群体任务效果可能更好。从环境角度来看，训练大型模型是昂贵的，尽管努力使用高效数据中心和抵消排放的CO2。然而，先前的研究表明，在模型推理过程中产生了最多的环境影响，并且在这方面MoEs更加高效[47]；LIMoE自然是一个有效、大规模多模态基础模型。
未来工作：从这里可以有许多有趣的方向。对于多个模态之间的路由干扰仍不完全理解。总体而言，将MoEs应用于NLP所得出的结论并没有完美地适用于Vision领域，反之亦然，在这里我们再次看到图像和文本之间存在不同行为。自然地，应该探索更多类型扩展；即使只有两种类型，我们也能看到不同数据类型和路由算法之间产生了迷人的相互作用，并且随着更多类型参与其中会变得更加困难和有趣。始终还有更多要学习的类型以及更大规模要构建的模型：稀疏模型提供了一种非常自然地方式来在处理非常不同任务和数据时进行扩展，并且我们期待在这个领域看到更多研究成果。
# 3.引言
最近，稀疏激活的专家混合（MoE）模型已经被广泛应用于扩大视觉[1, 2]和文本模型[3, 4]。使用MoEs的主要动机是在控制计算成本的同时扩展模型参数。然而，这些模型还有其他好处；例如，稀疏性可以防止连续学习中的灾难性遗忘[5]，并且通过提供方便的归纳偏差可以改善多任务学习[6]的性能。
鉴于每个单独领域取得的成功以及稀疏模型可能更好地处理不同任务的直觉，我们探索了将MoEs应用于多模态建模。我们朝着这个方向迈出了第一步，并研究了同时处理图像和文本表示形式的模型。具体来说，我们训练了一个单一多模态架构，通过对比学习来对齐图像和文本表示形式[7]。
当使用先前单一语言或图像建模中提出的设置时[8, 1] ，我们发现将多种表征输入到单一架构中会导致MoEs特有的新故障状态。为了克服这些问题，我们提出了一组基于信息熵正则化的方法，以稳定训练并提高性能。我们将得到的模型称为LIMoE（语言-图像MoE）。
我们训练了一系列LIMoE模型，它们在计算匹配的密集基线上表现出色。我们将其扩展到一个庞大的5.6B参数LIMoE-H/14，每个标记应用675M个参数。当在ImageNet-2012 [9]上进行零样本评估[7]时，它达到了84.1%的准确率，与利用特定于模态的预训练和特征提取器，并且每个标记应用3-4倍更多参数的双塔模型相竞争。
总结一下，我们的贡献如下：
- 我们提出了LIMoE，这是第一个大规模多模态专家混合模型。
- 我们详细展示了先前用于正则化专家混合模型的方法在多模态学习方面存在不足，并提出了一种新的基于熵的正则化方案来稳定训练过程。
- 我们证明LIMoE可以在不同架构尺度上进行泛化，在等效密集模型上，零样本ImageNet准确率相对提高了7%至13%。进一步扩展后，LIMoE-H/14实现了84.1%的零样本ImageNet准确率，与具有每个模态主干和预训练的SOTA对比模型相当。
- 最后，我们进行消融实验和分析以理解该模型的行为和我们设计决策。
# 4.Multimodal Mixture of Experts
![](./img/CleanShot%202023-10-24%20at%2010.16.06@2x.png)
> 图1：LIMoE，一种稀疏激活的多模态模型，处理图像和文本，利用条件计算以无关模态的方式分配令牌。

多模态对比学习通常使用独立的每种模态编码[7, 10]。也就是说，分别训练了用于提供相应模态m的每个输入的最终表示的单独模型fm。在图像和文本输入（i和t）的情况下，我们有zi = fimage(i)和zt = ftext(t)。对于图像和文本的对比学习，这种方法会导致一个“双塔”架构，每个模态一个。我们研究了一种单塔设置，其中一个单一模型被共享给所有模态，如图1所示。这种单塔设计提供了更高的普适性和可扩展性，并具有跨模式和跨任务知识传递的潜力。接下来我们将介绍LIMoE架构和训练过程。
## 2.1 Multimodal contrastive learning
给定n对图像和文本标题$\{(\mathbf{i}_j,\mathbf{t}_j)\}_{j=1}^n$ ，模型学习表示$\mathcal{Z}_n=\{(\mathbf{z_{i}}_j,\mathbf{z_{t}}_j)\}_{j=1}^n$ ，使得与配对输入相对应的表示在特征空间中比未配对输入的表示更接近。具有学习温度T的对比训练目标[7, 11]为：
$\mathcal{L}_j\left(\mathcal{Z}_n\right)=\underbrace{-\frac{1}{2} \log \frac{e^{\left\langle\mathbf{z}_{\mathbf{i}_j}, \mathbf{z}_{\mathbf{t}_j}\right\rangle / T}}{\sum_{k=1}^n e^{\left\langle\mathbf{z}_{\mathbf{i}_j}, \mathbf{z}_{\mathbf{t}_k}\right\rangle / T}}}_{\text {image-to-text loss }} \underbrace{-\frac{1}{2} \log \frac{e^{\left\langle\mathbf{z}_{\mathbf{i}_j}, \mathbf{z}_{\mathbf{t}_j}\right\rangle / T}}{\sum_{k=1}^n e^{\left\langle\mathbf{z}_{\mathbf{i}_k}, \mathbf{z}_{\mathbf{t}_j}\right\rangle / T}}}_{\text {text-to-image loss }}$.
## 2.2 The LIMoE  Architecture


